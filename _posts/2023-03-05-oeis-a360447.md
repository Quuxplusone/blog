---
layout: post
title: "Computing OEIS A360447"
date: 2023-03-05 00:01:00 +0000
tags:
  data-structures
  math
---

Last week an interesting integer sequence popped up on
[/r/CasualMath](https://www.reddit.com/r/CasualMath/comments/11ep7ml/sequence_built_by_iterative_insertion_of_integers/)
and then OEIS: [OEIS A360447](https://oeis.org/A360447). This isn't a "numerical" sequence per se: it's a permutation of
the positive integers achieved by the following rule:

- Start with the list `0, 1, 2`.
- For each integer `i`, in order, starting with `3`, find the two adjacent integers in the list which sum to `i`
    and add `i` between them. For example, `3` goes between `1` and `2`; then `4` goes between `1` and `3`; producing
    the list `0, 1, 4, 3, 2` so far.
- Now `5` could go between `1, 4` or between `3, 2`. When you have multiple options, choose the pair with the
    smallest absolute difference: `(3 - 2) = 1` is smaller than `(4 - 1) = 3`, so `5` goes between `3` and `2`.
- Now there's no pair of adjacent integers that sums to `6`. When you have no options, just insert the integer at
    the end of the list; producing `0, 1, 4, 3, 5, 2, 6` so far.
- Consider the prefix `0, 1, 4`. Notice that the only numbers that could ever _possibly_ be inserted in between
    these elements are `1` and `5`, and we've already passed those values: we're working on `i=7` now. So `0, 1, 4`
    is guaranteed never to change after this point — it's a prefix of the "true" sequence OEIS A360447.

You can compute this sequence by brute force something like this:

    std::vector<int> v = {0, 1, 2};
    for (int i=3; i < MAX; ++i) {
        auto p = find_insertion_point(v, i);
        v.insert(p, i);
    }

But finding the insertion point, with no other bookkeeping to speed the computation, takes O(n) time.
So does `v.insert`. We can do vastly better with an algorithm like this:

    std::list<int> v = {0, 1, 2};
    std::map<int, ListIterator> sums = {
        { 3, std::prev(v.end()) },
    };
    for (int i=3; i < MAX; ++i) {
        auto it = sums.find(i);
        if (it == sums.end()) {
            v.push_back(i);
            maybe_update_sums(std::prev(v.end()));
        } else {
            auto p = it->second;
            p = v.insert(p, i);
            sums.erase(it);
            maybe_update_sums(p);
            maybe_update_sums(std::next(p));
        }
    }

where `maybe_update_sums(pos)` checks to see if `pos` is now the best place to insert the number `i` in the future,
and if so, updates the `sums` map with `{ i, pos }`.

Using this algorithm, we're bottlenecked mainly on memory — and what a bottleneck it is! We can save some memory by
observing that we'll never look up any integer bigger than `MAX` in `sums`, so we never have to insert sums bigger
than `MAX` into `sums`. We can save more memory, and also save a lot of time, by switching from `std::list` to
`std::forward_list`: a list node holding an `int` plus a `next` pointer is only 66% the size of a list node holding
that `int` plus `next` and `prev` pointers. It turns out we can also save a lot of time by switching from `std::map`
to `std::unordered_map`.

I tried various low-level tweaks on the list data structure, but nothing really helped.
[`plf::list`](https://github.com/mattreecebentley/plf_list) is faster than `std::list` for this workload,
but not as fast as `std::forward_list`, and sadly there's no `plf::forward_list` to compare against.
I tried a custom `forward_list`-alike, inspired by `plf::list`'s allocation strategy, which "allocates" nodes
out of a giant array it's preallocated: that saves memory, but (surprisingly) still isn't faster than `std::forward_list`.

The remaining bottleneck (besides just finding an even better algorithm) is `std::map`. We can save time
by switching to `std::unordered_map`. In fact we can save _tons_ of time by just preallocating a massive array
(a "hash map with max load factor 1"); this also saves memory, because the `unordered_map` wastes space on `next` pointers
for its chained buckets, and if we use a massive array then we don't need any `next` pointers. This lowers our
memory usage to the probably-minimal 8 bytes per list element and 4 bytes per map element.

Find a snapshot of my current code [here](/blog/code/2023-03-05-oeis-a360447.cpp). On my laptop, it chugs
through the first 100 million integers, producing entries `a(0)=0` through `a(59)=44289045`
of OEIS A360447, in 33 seconds.

Tackling the first billion integers, it produces `a(95)=362806936`
in 91 seconds:

    $ g++ -std=c++20 -O2 -march=native "-DMAX=1'000'000'000" \
          -DUSE_CUSTOM_LIST -DUSE_ARRAY_MAP \
          2023-03-05-oeis-a360447.cpp
    $ time ./a.out
    [...]
    0, 1, 4, 11, 29, 47, 18, 61, 165, 434, 703, 1675, 972, 2213,
    10093, 17973, 25853, 59586, 33733, 7880, 21427, 56401, 204177,
    147776, 91375, 217724, 126349, 414021, 287672, 161323, 34974,
    48521, 13547, 5667, 9121, 12575, 28604, 16029, 3454, 1241, 269,
    1180, 3271, 2091, 911, 2464, 11409, 20354, 90361, 250729, 160368,
    551111, 1492965, 941854, 390743, 1011861, 621118, 2714847,
    15667964, 44289045, 161488216, 278687387, 117199171, 72910126,
    174441333, 450413873, 275972540, 101531207, 28621081, 12953117,
    36144504, 23191387, 33429657, 10238270, 7523423, 19855422,
    52042843, 32187421, 44519420, 12331999, 4808576, 21328033,
    59175523, 156198536, 253221549, 350244562, 97023013, 231893516,
    134870503, 37847490, 16519457, 61269252, 167288299, 273307346,
    106019047, 362806936
    (i=982401761, t=83s, next update at i=1345208697)

    real 1m30.922s
    user 1m23.649s
    sys  0m6.233s

`a(96)=1345208697` takes another five minutes beyond that, and
twice as much RAM. I doubt I'll be able to push it much further.

----

See also:

- ["The quest for the fastest linked list"](https://johnysswlab.com/the-quest-for-the-fastest-linked-list/) (Ivica Bogosavljević, August 2021)
